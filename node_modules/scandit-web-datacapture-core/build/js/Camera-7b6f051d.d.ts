/// <reference types="emscripten" />
import { Serializable } from './private/Serializable.js';
import { WatermarkStack } from './private/FrameReaders/WatermarkStack.js';
import { Optional } from './tsHelper.js';
import { Size, Orientation, MarginsWithUnitJSON, PointWithUnitJSON, Anchor, MarginsWithUnit, PointWithUnit, Point, Quadrilateral, JSONType, PointJSON } from './Common.js';
import { DataCaptureContextSettings, DataCaptureContextSettingsJSON } from './DataCaptureContextSettings.js';
import { LogoStyle, FocusGestureJSON, ZoomGestureJSON, FocusGesture, ZoomGesture } from './DataCaptureViewPlusRelated.js';
import { Control } from './ViewControls.js';
import { DidTapCustomLocationsViewListener, StateToRender } from './private/CustomLocationsView.js';
import { AnchorPositions } from './private/AnchorPositions.js';
import { Logger } from './logger.js';
import { ProgressInfo } from './LoadingStatus.js';

declare enum CameraPosition$1 {
    WorldFacing = "worldFacing",
    UserFacing = "userFacing"
}
declare enum CameraResolutionConstraint$1 {
    ULTRA_HD = 0,
    FULL_HD = 1,
    HD = 2,
    SD = 3,
    NONE = 4
}
declare enum AspectRatio {
    AUTO = "auto",
    FOUR_TO_THREE = "fourToThree",
    SIXTEEN_TO_NINE = "sixteenToNine"
}
interface DeviceCamera$1 {
    position: CameraPosition$1;
    label: string;
    deviceId: string;
    currentResolution?: VideoFrameResolution;
}
/**
 * A helper object to interact with cameras.
 */
declare namespace CameraAccess$1 {
    /**
     * Overrides for main camera for a given camera position on a desktop/laptop device, set when accessing an initial camera.
     */
    const mainCameraForPositionOverridesOnDesktop: Map<CameraPosition$1, DeviceCamera$1>;
    /**
     *
     * To be accessed directly only for tests.
     *
     * The mapping from deviceIds to camera objects.
     */
    const deviceIdToCameraObjects: Map<string, DeviceCamera$1>;
    /**
     *
     * To be accessed directly only for tests.
     *
     * The list of inaccessible deviceIds.
     */
    const inaccessibleDeviceIds: Set<string>;
    function setMainCameraForPositionOverridesOnDesktop(cameraPosition: CameraPosition$1, deviceCamera: DeviceCamera$1): void;
    /**
     * used mainly for testing
     */
    function clearMainCameraForPositionOverridesOnDesktop(): void;
    /**
     *
     * @param label The camera label.
     * @returns Whether the label identifies the camera being the iOS front (main) camera one.
     */
    function isIOSFrontCameraLabel(label: string): boolean;
    /**
     *
     * @param label The camera label.
     * @returns Whether the label identifies the camera being the iOS back (main) camera one.
     */
    function isIOSBackCameraLabel(label: string): boolean;
    /**
     *
     * @param label The camera label.
     * @returns Whether the label identifies the camera being the iOS Back Dual camera one.
     */
    function isIOSBackDualWideCameraLabel(label: string): boolean;
    /**
     *
     * @param label The camera label.
     * @returns Whether the label identifies the camera being the iOS UltraWide back camera one.
     */
    function isIOSUltraWideBackCameraLabel(label: string): boolean;
    /**
     *
     * Get the main camera for the given camera position.
     *
     * @param cameras The array of available [[DeviceCamera]] objects.
     * @param cameraPosition The wanted camera position.
     * @returns The main camera matching the wanted camera position.
     */
    function getMainCameraForPosition(cameras: DeviceCamera$1[], cameraPosition: CameraPosition$1): DeviceCamera$1 | undefined;
    /**
     *
     * Sort the given cameras in order of priority of access based on the given camera position.
     *
     * @param cameras The array of available [[DeviceCamera]] objects.
     * @param cameraPosition The preferred camera position.
     * @returns The sorted cameras.
     */
    function sortCamerasForCameraPosition<DeviceCameraLike extends DeviceCamera$1 = DeviceCamera$1>(cameras: DeviceCameraLike[], cameraPosition: CameraPosition$1): DeviceCameraLike[];
    /**
     *
     * Adjusts the camera's information based on the given currently active video stream.
     *
     * @param mediaStream The currently active `MediaStream` object.
     * @param camera The currently active [[Camera]] object associated with the video stream.
     */
    function adjustCameraFromMediaStream(mediaStream: MediaStream, camera: DeviceCamera$1): void;
    /**
     * Get a list of cameras (if any) available on the device, a camera access permission is requested to the user
     * the first time this method is called if needed.
     *
     * If the user denies the necessary camera access permission, a list of cameras with the correct amount of devices is
     * returned in any case, but the cameras will have no available (empty) label and deviceId and can thus not be
     * accessed.
     *
     * If the browser is incompatible the returned promise is rejected with a `UnsupportedBrowserError` error.
     *
     * When refreshing available devices, if updated deviceId information is detected, cameras' deviceId are updated
     * accordingly. This could happen after a camera access and stop in some situations.
     *
     * @param refreshDevices Force a call to refresh available video devices even when information is already available.
     * @param cameraAlreadyAccessed Hint that a camera has already been accessed before, avoiding a possible initial
     * camera access permission request on the first call, in cases this cannot be already reliably detected.
     * @returns A promise resolving to the array of available [[Camera]] objects (could be empty).
     */
    function getCameras(refreshDevices?: boolean, cameraAlreadyAccessed?: boolean): Promise<DeviceCamera$1[]>;
    /**
     *
     * Get the *getUserMedia* *video* parameters to be used given a resolution fallback level and the browser used.
     *
     * @param cameraResolutionConstraint The resolution constraint.
     * @returns The resulting *getUserMedia* *video* parameters.
     */
    function getUserMediaVideoParameters(cameraResolutionConstraint: CameraResolutionConstraint$1, preferredAspectRatio?: AspectRatio): MediaTrackConstraints;
    /**
     *
     * Mark a camera to be inaccessible and thus excluded from the camera list returned by [[getCameras]].
     *
     * @param camera The camera to mark to be inaccessible.
     */
    function markCameraAsInaccessible(camera: DeviceCamera$1): void;
    /**
     *
     * Try to access a given camera for video input at the given resolution level.
     *
     * If a camera is inaccessible because of errors, then it's added to the inaccessible device list. If the specific
     * error is of type `OverconstrainedError` or `NotReadableError` however, this procedure is done later on via a
     * separate external logic; also, in case of an error of type `NotAllowedError` (permission denied) this procedure is
     * not executed, in order to possibly recover if and when the user allows the camera to be accessed again.
     * This is done to allow checking if the camera can still be accessed via an updated deviceId when deviceId
     * information changes, or if it should then be confirmed to be considered inaccessible.
     *
     * Depending on parameters, device features and user permissions for camera access, any of the following errors
     * could be the rejected result of the returned promise:
     * - `AbortError`
     * - `NotAllowedError`
     * - `NotFoundError`
     * - `NotReadableError`
     * - `SecurityError`
     * - `OverconstrainedError`
     *
     * @param cameraResolutionConstraint The resolution constraint.
     * @param camera The camera to try to access for video input.
     * @returns A promise resolving to the `MediaStream` object coming from the accessed camera.
     */
    function accessCameraStream(camera: DeviceCamera$1, cameraResolutionConstraint: CameraResolutionConstraint$1, preferredAspectRatio?: AspectRatio): Promise<MediaStream>;
}

/**
 * these are the public exports from CameraAccess
 */
declare namespace CameraAccess {
    function getCameras(refreshDevices?: boolean, cameraAlreadyAccessed?: boolean): Promise<DeviceCamera[]>;
}
interface DeviceCamera {
    position: CameraPosition$1;
    label: string;
    deviceId: string;
}

declare enum FrameSourceState {
    On = "on",
    Off = "off",
    Standby = "standby",
    Starting = "starting",
    Stopping = "stopping",
    BootingUp = "bootingUp",
    WakingUp = "wakingUp",
    GoingToSleep = "goingToSleep",
    ShuttingDown = "shuttingDown"
}
declare enum TorchState {
    On = "on",
    Off = "off"
}
declare enum CameraPosition {
    WorldFacing = "worldFacing",
    UserFacing = "userFacing"
}
declare enum VideoResolution {
    Auto = "auto",
    HD = "hd",
    FullHD = "fullHd",
    UHD4K = "uhd4k"
}
declare enum FocusGestureStrategy {
    None = "none",
    Manual = "manual",
    ManualUntilCapture = "manualUntilCapture",
    AutoOnLocation = "autoOnLocation"
}
interface FrameSourceListener {
    didChangeState?: (frameSource: FrameSource, newState: FrameSourceState) => void;
}
interface FrameSourceJSON {
    type: string;
}
interface FrameSource extends Serializable<FrameSourceJSON> {
    readonly desiredState: FrameSourceState;
    getCurrentState: () => FrameSourceState;
    switchToDesiredState: (desiredState: FrameSourceState) => Promise<void>;
    addListener: (listener: FrameSourceListener) => void;
    removeListener: (listener: FrameSourceListener) => void;
}
interface CameraSettingsJSONBase {
    preferredResolution: string;
    zoomFactor: number;
    zoomGestureZoomFactor: number;
    api?: number;
}
interface CameraSettingsFromJSON extends CameraSettingsJSONBase {
    focusGestureStrategy: string;
}
interface CameraSettingsJSON extends CameraSettingsJSONBase {
    focus: {
        focusGestureStrategy: string;
        [key: string]: any;
    };
    [key: string]: any;
}
declare function isCameraFrameSource(frameSource?: FrameSource | null): frameSource is Camera;
declare class CameraSettings implements Serializable<CameraSettingsJSON> {
    preferredResolution: VideoResolution;
    zoomFactor: number;
    zoomGestureZoomFactor: number;
    private focus;
    get focusGestureStrategy(): FocusGestureStrategy;
    set focusGestureStrategy(newStrategy: FocusGestureStrategy);
    private static fromJSON;
    constructor();
    constructor(settings: CameraSettings);
    setProperty(name: string, value: any): void;
    getProperty(name: string): any;
    /**
     * The resulting JSON must also contain properties set on the object itself ("hidden" properties)
     */
    toJSONObject(): CameraSettingsJSON & Record<string, any>;
}

declare abstract class FrameReaderAbstract {
    colorType: ColorType;
    protected readonly _contextWebGL: WebGLRenderingContext;
    protected readonly _maxPoolCapacity: number;
    protected readonly _minPoolCapacity: number;
    /**
     * In mobile applications, particularly on Android, capturing frames at a slow rate can be a common issue,
     * especially in scenarios involving barcode tracking. Using a stack becomes valuable in such situations
     * because it allows us to capture next frame with pixel data while the engine is still processing the previous one,
     * eliminating the need to wait for the engine to finish before capturing the next frame.
     */
    protected _framePool: Optional<WatermarkStack<Uint8ClampedArray>>;
    constructor(contextWebGL: WebGLRenderingContext, options?: {
        maxPoolCapacity: number;
        minPoolCapacity: number;
    } | undefined);
    abstract readFromSource(source: TexImageSource): FrameCapture;
    abstract setup(): void;
    recycle(pixelsData: Uint8ClampedArray): void;
    abstract dispose(): void;
}

declare enum ColorType {
    RGBA = "RGBA",
    GRAYSCALE = "GRAYSCALE"
}
declare class FrameReader extends FrameReaderAbstract {
    colorType: ColorType;
    private _framebuffer;
    private _texture;
    private _frameSize;
    private get _initialized();
    readFromSource(source: TexImageSource): FrameCapture;
    setup(): void;
    dispose(): void;
    private updateFrameSizeIfNeeded;
}

interface DataCaptureContextListener {
    didChangeStatus?: (context: DataCaptureContext$1, contextStatus: ContextStatus) => void;
    didStartObservingContext?: (context: DataCaptureContext$1) => void;
    didChangeFrameSource?: (context: DataCaptureContext$1, frameSource: FrameSource | null) => void;
}
interface ContextStatusJSON {
    code: number;
    isValid: boolean;
    message: string;
}
declare class ContextStatus {
    private _message;
    private _code;
    private _isValid;
    private static fromJSON;
    get message(): string;
    get code(): number;
    get isValid(): boolean;
}
declare enum PrivateMirrorAxis {
    None = "None",
    X = "X",
    Y = "Y"
}

interface DataCaptureOverlay extends Serializable {
    toJSONObject: () => any;
}
interface DataCaptureViewListener {
    didChangeSize?: (view: DataCaptureView$1, size: Size, orientation: Orientation) => void;
}
interface DataCaptureViewJSON {
    scanAreaMargins: MarginsWithUnitJSON;
    pointOfInterest: PointWithUnitJSON;
    logoAnchor: Anchor;
    logoOffset: PointWithUnitJSON;
    logoHidden: boolean;
    logoStyle: LogoStyle;
    overlays: any[];
    controls: any[];
    focusGesture: FocusGestureJSON | null;
    zoomGesture: ZoomGestureJSON | null;
}
declare class DataCaptureView$1 implements Serializable<DataCaptureViewJSON> {
    focusGesture: FocusGesture | null;
    zoomGesture: ZoomGesture | null;
    private _scanAreaMargins;
    private _pointOfInterest;
    private _logoStyle;
    private _logoAnchor;
    private _logoOffset;
    private _cameraRecoveryText;
    private _context;
    private readonly overlays;
    private readonly controls;
    private gestureRecognizer;
    private readonly controlWidgets;
    private containerElement;
    private cameraPaintboardElement?;
    private singleImageUploaderPaintboardElement?;
    private videoElement?;
    private visibilityListener;
    private videoPauseListener;
    private cameraRecoveryListener;
    private controlsElement;
    private cameraRecoveryElement;
    private errorElement;
    private hintContainerElement;
    private hintElement;
    private canvasElement;
    private frozenFrame;
    private frozenFrameCanvas;
    private _canvasDrawer;
    private readonly listeners;
    private htmlElement?;
    private htmlElementState?;
    private lastHtmlElementState;
    private isVideoElementDetached;
    private progressBarView;
    private customLocationsView;
    private lastFrameSourceState;
    private singleImageUploaderView;
    private hiddenProperties;
    constructor();
    get scanAreaMargins(): MarginsWithUnit;
    set scanAreaMargins(margins: MarginsWithUnit);
    get pointOfInterest(): PointWithUnit;
    set pointOfInterest(pointOfInterest: PointWithUnit);
    get logoStyle(): LogoStyle;
    set logoStyle(logoStyle: LogoStyle);
    get logoAnchor(): Anchor;
    set logoAnchor(logoAnchor: Anchor);
    get logoOffset(): PointWithUnit;
    set logoOffset(logoOffset: PointWithUnit);
    get cameraRecoveryText(): string;
    /**
     * @deprecated 6.21.0
     */
    set cameraRecoveryText(cameraRecoveryText: string);
    private get width();
    private get height();
    private get canvasDrawer();
    /**
     * The current context as a PrivateDataCaptureContext
     */
    private get privateContext();
    static forContext(context: DataCaptureContext$1 | null): Promise<DataCaptureView$1>;
    showProgressBar(): void;
    hideProgressBar(): void;
    setProgressBarPercentage(percentage: number | null): void;
    setProgressBarMessage(message: string): void;
    getContext(): DataCaptureContext$1 | null;
    setContext(context: DataCaptureContext$1 | null): Promise<void>;
    connectToElement(element: HTMLElement): void;
    detachFromElement(): void;
    addOverlay(overlay: DataCaptureOverlay): Promise<void>;
    removeOverlay(overlay: DataCaptureOverlay): Promise<void>;
    addListener(listener: DataCaptureViewListener): void;
    removeListener(listener: DataCaptureViewListener): void;
    /**
     * Converts a point in the coordinate system of the last visible frame and maps it to a coordinate in the view.
     * It does *not* take into account if the frameSource is mirrored.
     */
    viewPointForFramePoint(point: Point): Point;
    viewQuadrilateralForFrameQuadrilateral(quadrilateral: Quadrilateral): Quadrilateral;
    addControl(control: Control): void;
    removeControl(control: Control): void;
    toJSONObject(): DataCaptureViewJSON;
    isCameraRecoveryVisible(): boolean;
    setCameraRecoveryVisible(visible: boolean): void;
    allowPictureInPicture(allow: boolean): Promise<void>;
    protected viewAnchorPositionsForFrameAnchorPositions(anchorPositions: AnchorPositions): AnchorPositions;
    protected setDidTapCustomLocationsViewListener(didTapViewListener: DidTapCustomLocationsViewListener): void;
    protected renderCustomLocationsView(state: StateToRender): void;
    private removeStyles;
    private clearHtmlElementContent;
    private setupHtmlElement;
    private setupHtmlElementSingleImageUploader;
    private setupHtmlElementVisibility;
    private createStyles;
    private htmlElementDidChange;
    private htmlElementDisconnected;
    private handleVideoDisplay;
    private isCanvasDrawerWithMetrics;
    private onWorkerMessage;
    private drawEngineCommands;
    private displayError;
    private clearError;
    private displayHint;
    private hideHint;
    private updateHint;
    private updateAnchor;
    private controlsUpdated;
    private redrawControls;
    private getControlWidget;
    private onFrameSourceChange;
    private onCameraStateChanged;
    private setVideoElementOpacity;
    private onSingleImageUploaderSettingsChange;
    private handleVideoPause;
    private setHiddenProperty;
    private onVisibilityChange;
    private cameraRecovery;
    private freezeFrame;
    private unfreezeFrame;
}

type CommandAndPayload<A, C> = A extends {
    command: C;
} ? A : never;
type WorkerCommandPayload<C> = Omit<CommandAndPayload<AnyDataCaptureActionMessage, C>, "command" | "id">;
type WorkerListener = (event: DataCaptureCallbackMessage) => any;
declare enum OverrideState {
    Auto = "auto",
    Off = "off",
    On = "on"
}
interface DataCaptureLoaderOptions {
    libraryLocation: string;
    verifyResponseHash: boolean;
    preloadEngine?: boolean;
    loadProgressNotifier?: (info: ProgressInfo) => void;
    logLevel?: Logger.Level;
    poorMansBenchmarkLogs?: boolean;
    overrideSimdSupport: OverrideState;
    overrideThreadsSupport: OverrideState;
    highEndBlurryRecognition?: boolean;
}
/**
 * The DataCaptureLoader class is used by the main thread, it instantiates the worker
 * and sends commands to it. It represents thus the main communication channel
 * between the main thread and the engine running in the worker.
 */
declare class DataCaptureLoader {
    highEndBlurryRecognition?: boolean;
    protected overrideThreadsSupport: OverrideState;
    protected overrideSimdSupport: OverrideState;
    protected verifyResponseHash: boolean;
    protected _dataCaptureWorker?: DataCaptureWorker;
    protected readonly libraryLocation: string;
    /**
     * Mainly useful for FS when merging preloaded data (blurry tables preloading).
     */
    protected readonly isPreloadEngine: boolean;
    protected workerCommandId: number;
    protected readonly workerTasks: Map<number, {
        resolve: (...arguments_: any[]) => any;
        reject: (...arguments_: any[]) => any;
        command: string;
    }>;
    protected readonly workerListeners: WorkerListener[];
    protected workerMessageListener: (event_: MessageEvent<DataCaptureCallbackMessage>) => void;
    protected constructor(options: DataCaptureLoaderOptions);
    get dataCaptureWorker(): DataCaptureWorker;
    protected get name(): string;
    static create(options: DataCaptureLoaderOptions): Promise<DataCaptureLoader>;
    load(): Promise<WorkerResponse<"loadLibrary">>;
    /**
     * Send a task (i.e. a command) to the worker. Every task sent has a corresponding Promise object which
     * gets resolved when the worker has processed the request. The tasks are identified by an id which is
     * sent along with the data by both sides.
     */
    workerCommand<C extends DataCaptureActionMessageKey>(command: C, payload: WorkerCommandPayload<C>, transferables?: Transferable[]): Promise<WorkerResponse<C>>;
    terminateDataCaptureWorker(disposeContext?: boolean): Promise<void>;
    addWorkerListener(listener: WorkerListener): void;
    removeWorkerListener(listener: WorkerListener): void;
    protected onWorkerMessage(event_: MessageEvent<DataCaptureCallbackMessage>): void;
}

interface Change {
    type: "addControl" | "addOverlay" | "cameraSettings" | "frameSourceState" | "removeControl" | "removeOverlay" | "singleImageModeUploaderSettings" | "torchState" | "viewChange";
    newValue: any;
}
type PrivateChangeSet = Change[];
interface PrivateDataCaptureMode {
    type: "barcodeCapture" | "idCapture";
    _context: Optional<DataCaptureContext$1>;
    attachedToContext: (context: DataCaptureContext$1) => void;
    detachedFromContext: () => Promise<void>;
}
interface DataCaptureMode extends Serializable {
    isEnabled(): boolean;
    setEnabled(enabled: boolean): Promise<void>;
    context: Optional<DataCaptureContext$1>;
}
interface DataCaptureModeJSON<S = JSONType> {
    type: "barcodeCapture" | "barcodeTracking" | "idCapture" | "sparkScan";
    enabled: boolean;
    settings: S;
}
interface PrivateDataCaptureComponent {
    _context: DataCaptureContext$1;
}
type DataCaptureComponentJSON = JSONType;
interface DataCaptureComponent extends Serializable<DataCaptureComponentJSON> {
    readonly id: string;
}
interface PrivateDataCaptureContextOptions {
    deviceName?: string | null;
    dataCaptureInstance?: DataCaptureLoader;
    delayedRegistration?: boolean;
}
interface PrivateDataCaptureContext {
    _frameSource?: FrameSource | null;
    modes: DataCaptureMode[];
    components: DataCaptureComponent[];
    initialize: () => Promise<void>;
    update: (changeSet?: PrivateChangeSet) => Promise<void>;
    addComponent: (component: DataCaptureComponent) => Promise<void>;
    dataCaptureInstance: DataCaptureLoader;
    sendFrameToProcessor: (capture: FrameCapture) => Promise<WorkerResponse<"processFrame">>;
    subscribeToWorkerMessages: (listener: (message: DataCaptureCallbackMessage) => void) => void;
    unsubscribeToWorkerMessages: (listener: (message: DataCaptureCallbackMessage) => void) => void;
    hasEnabledMode: () => boolean;
    workerCommand: (cmd: string, data: any) => void;
    new (licenseKey: string, options: PrivateDataCaptureContextOptions): DataCaptureContext$1;
}
interface DataCaptureContextCreationOptions {
    deviceName?: string;
    licenseKey?: string;
    settings?: DataCaptureContextSettings;
}
interface RuntimeEnvironment {
    deviceOS: string;
    browser: string;
    browserVersion: string;
    deviceModelName: string;
}
interface DataCaptureContextJSON extends RuntimeEnvironment {
    framework: string;
    settings: DataCaptureContextSettingsJSON;
    licenseKey: string;
    deviceName: string;
    frameSource: FrameSourceJSON | null;
    modes: DataCaptureModeJSON[];
    components: DataCaptureComponentJSON[];
    view: DataCaptureViewJSON | null;
}
type PrivateFrameHandler = (frame: FrameCapture) => Promise<void>;
declare class DataCaptureContext$1 implements Serializable<DataCaptureContextJSON> {
    static deviceID: string;
    private readonly framework;
    private readonly runtimeEnvironment;
    private settings;
    private readonly licenseKey;
    private readonly deviceName;
    private _frameSource;
    private _view;
    private readonly modes;
    private readonly components;
    private readonly listeners;
    private readonly cameraPropertiesReportListener;
    private readonly cameraAccessErrorListener;
    private readonly onWorkerMessageListener;
    private readonly onVisibilityChangeListener;
    private readonly dataCaptureInstance;
    private readonly delayedRegistration;
    private readonly highEndBlurryRecognition;
    private readonly _frameHandlers;
    private constructor();
    get frameSource(): FrameSource | null;
    private get workerCommand();
    static create(): Promise<DataCaptureContext$1>;
    static createWithOptions(options: DataCaptureContextCreationOptions): Promise<DataCaptureContext$1>;
    /**
     * Disconnect the current frame source from the context and connect the new one. This process can happen multiple
     * times for the same frame source because of its initialisation (The mirroring info of a camera is only available
     * when it has started for example).
     * Trigger the "didChangeFrameSource" listeners only if the new frame source is different than the old one.
     */
    setFrameSource(frameSource: FrameSource | null): Promise<void>;
    addListener(listener: DataCaptureContextListener): void;
    flushAnalytics(): Promise<void>;
    removeListener(listener: DataCaptureContextListener): void;
    addMode(mode: DataCaptureMode): Promise<void>;
    removeMode(mode: DataCaptureMode): Promise<void>;
    removeAllModes(): Promise<void>;
    dispose(): Promise<void>;
    applySettings(settings: DataCaptureContextSettings): Promise<void>;
    toJSONObject(): DataCaptureContextJSON;
    private getView;
    private setView;
    private getAppName;
    private urlToHostname;
    private getParentDomain;
    private initialize;
    private subscribeToVisibilityChange;
    private unsubscribeToVisibilityChange;
    private requestFrameData;
    private sendFrameToProcessor;
    private sendFrameToHandlers;
    private sendFrameToSDC;
    private registerFrameHandler;
    private unregisterFrameHandler;
    private onVisibilityChange;
    private onWorkerMessage;
    private subscribeToCameraManagerEvents;
    private reportCameraProperties;
    private onCameraAccessError;
    private update;
    private updateContext;
    private getViewInfo;
    private getMirrorAxisForFrameSource;
    private addComponent;
    private subscribeToWorkerMessages;
    private unsubscribeToWorkerMessages;
    private hasEnabledMode;
}

/**
 * MESSAGES (ACTIONS) SENT TO THE WORKER
 */
type DataCaptureActionMessageKey = "createContext" | "deleteFrameData" | "dispose" | "documentVisibility" | "extractCentaurusLicense" | "flushAnalytics" | "loadLibrary" | "onTap" | "processFrame" | "reportCameraProperties" | "requestFrameData" | "setFrameSource" | "setLogLevel" | "setPoorMansBenchmarkLogs" | "updateContext";
interface ExtractCentaurusLicenseResponse {
    centaurus: {
        licenseKey: string;
    };
}
interface RequestFrameDataResponse {
    data: Uint8ClampedArray | null;
}
type WorkerResponse<C> = C extends "processFrame" ? ProcessFrameParameters : C extends "extractCentaurusLicense" ? ExtractCentaurusLicenseResponse : C extends "requestFrameData" ? RequestFrameDataResponse : undefined;
interface DataCaptureActionMessage {
    command: DataCaptureActionMessageKey;
    id: number;
}
type LoadLibraryDataCaptureAction = DataCaptureActionMessage & LoadLibraryParameters & {
    command: "loadLibrary";
};
type CreateContextDataCaptureAction = CreateContextParameters & DataCaptureActionMessage & {
    command: "createContext";
};
type SetFrameSourceDataCaptureAction = DataCaptureActionMessage & SetFrameSourceParameters & {
    command: "setFrameSource";
};
type ProcessFrameDataCaptureAction = DataCaptureActionMessage & ProcessFrameParameters & {
    command: "processFrame";
};
type RequestFrameDataDataCaptureAction = DataCaptureActionMessage & {
    command: "requestFrameData";
    frameId: number;
};
type DeleteFrameDataDataCaptureAction = DataCaptureActionMessage & {
    command: "deleteFrameData";
    frameId: number;
};
type VisibilityChangeAction = DataCaptureActionMessage & {
    command: "documentVisibility";
    state: DocumentVisibilityState;
};
type UpdateContextDataCaptureAction = DataCaptureActionMessage & {
    command: "updateContext";
    context: DataCaptureContextJSON;
    view: UpdateContextParameters["view"];
};
type DisposeDataCaptureAction = DataCaptureActionMessage & {
    command: "dispose";
};
type FlushAnalyticsDataCaptureAction = DataCaptureActionMessage & {
    command: "flushAnalytics";
};
type ReportCameraPropertiesDataCaptureAction = DataCaptureActionMessage & ReportCameraPropertiesParameters & {
    command: "reportCameraProperties";
};
type SetLogLevelDataCaptureAction = DataCaptureActionMessage & {
    command: "setLogLevel";
    level: Logger.Level;
};
type SetPoorMansBenchmarkLogsAction = DataCaptureActionMessage & {
    command: "setPoorMansBenchmarkLogs";
    enable: boolean;
};
type ExtractCentaurusLicenseDataCaptureAction = DataCaptureActionMessage & {
    command: "extractCentaurusLicense";
    licenseKey: string;
};
type OnTapAction = DataCaptureActionMessage & {
    command: "onTap";
    point: PointJSON;
};
type AnyDataCaptureActionMessage = CreateContextDataCaptureAction | DeleteFrameDataDataCaptureAction | DisposeDataCaptureAction | ExtractCentaurusLicenseDataCaptureAction | FlushAnalyticsDataCaptureAction | LoadLibraryDataCaptureAction | OnTapAction | ProcessFrameDataCaptureAction | ReportCameraPropertiesDataCaptureAction | RequestFrameDataDataCaptureAction | SetFrameSourceDataCaptureAction | SetLogLevelDataCaptureAction | SetPoorMansBenchmarkLogsAction | UpdateContextDataCaptureAction | VisibilityChangeAction;
/**
 * MESSAGES EMITTED BY THE WORKER
 */
type DataCaptureCallbackMessageKeys = "contextDidChangeStatus" | "didStartObservingContext" | "draw" | "hideHint" | "loadLibraryProgress" | "performanceMetricsReport" | "showHint" | "successFeedback" | "updateHint" | "workerTaskId";
interface BaseDataCaptureCallbackMessage {
    type: DataCaptureCallbackMessageKeys;
}
interface LoadLibraryProgressMessage {
    type: "loadLibraryProgress";
    payload: ProgressInfo;
}
interface ConsoleWorkerMessage {
    type: "console";
    payload: string;
}
interface WorkerTaskIdWorkerMessage extends BaseDataCaptureCallbackMessage {
    type: "workerTaskId";
    command: string;
    id: number;
    error?: unknown;
    payload?: unknown;
}
type DrawWorkerMessage = BaseDataCaptureCallbackMessage & {
    type: "draw";
    payload: Uint8Array;
};
type DidChangeStatusWorkerMessage = BaseDataCaptureCallbackMessage & {
    type: "contextDidChangeStatus";
    payload: ContextStatusJSON;
};
type StartObservingContextWorkerMessage = BaseDataCaptureCallbackMessage & {
    type: "didStartObservingContext";
};
type SuccessFeedbackWorkerMessage = BaseDataCaptureCallbackMessage & {
    type: "successFeedback";
};
type ShowHintWorkerMessage = BaseDataCaptureCallbackMessage & {
    type: "showHint";
    payload: {
        text: string;
        style: HintStyle;
    };
};
type UpdateHintWorkerMessage = BaseDataCaptureCallbackMessage & {
    type: "updateHint";
    payload: {
        style: HintStyle;
    };
};
type HideHintWorkerMessage = BaseDataCaptureCallbackMessage & {
    type: "hideHint";
    payload: Record<string, never>;
};
type PerformanceMetricsReportMessage = BaseDataCaptureCallbackMessage & {
    type: "performanceMetricsReport";
    payload: PerformanceMetrics;
};
type DidTapTrackedBarcode = BaseDataCaptureCallbackMessage & {
    type: "didTapTrackedBarcode";
    payload: any;
};
type DataCaptureCallbackMessage = ConsoleWorkerMessage | DidChangeStatusWorkerMessage | DrawWorkerMessage | HideHintWorkerMessage | LoadLibraryProgressMessage | PerformanceMetricsReportMessage | ShowHintWorkerMessage | StartObservingContextWorkerMessage | SuccessFeedbackWorkerMessage | UpdateHintWorkerMessage | WorkerTaskIdWorkerMessage;
/**
 * OTHERS
 */
type PayloadForCommand<A, C> = A extends {
    command: C;
} ? A : never;
interface DataCaptureWorker extends Omit<Worker, "postMessage"> {
    onmessage: ((this: Worker, event_: MessageEvent & {
        data: unknown;
    }) => void) | null;
    postMessage: <C extends AnyDataCaptureActionMessage["command"]>(message: PayloadForCommand<AnyDataCaptureActionMessage, C>, transfer?: Transferable[]) => void;
}
interface EmscriptenClassHandle<Self = EmscriptenClassHandle<unknown>> {
    clone: () => Self;
    delete: () => void;
    isDeleted: () => boolean;
    deleteLater: () => void;
    isAliasOf: () => Self;
}
interface DataCaptureContext extends EmscriptenClassHandle {
    setCameraProperties: (deviceId: string, isFrontFacing: boolean, hasAutofocus: boolean) => void;
    addListener: (function_: unknown) => void;
    dispose: () => void;
    setFrameSource: (source: EmscriptenClassHandle) => void;
    flushAnalytics: () => void;
}
interface DataCaptureImageBufferFrameSource extends EmscriptenClassHandle {
    outputFrame: (address: number, width: number, height: number, format: unknown) => void;
}
interface GestureListener extends EmscriptenClassHandle<GestureListener> {
    onTap(point: string): void;
}
interface GestureRecognizer extends EmscriptenClassHandle {
    setGestureListener(gestureListener: GestureListener, flags: number): void;
}
interface DataCaptureView extends EmscriptenClassHandle {
    setViewSize: (w: number, h: number) => void;
    setNeedsRedrawDelegate: (delegate: unknown) => void;
    draw: () => void;
    getDrawCommands: () => Uint8Array;
    isViewRefreshHandlerSet: boolean;
    hintPresenterInitialized: () => boolean;
    setHintPresenter: (hintPresenter: unknown) => void;
    setGestureRecognizer: (recognizer: GestureRecognizer) => void;
}
interface JSONParseable {
    toJson: () => string;
}
interface DataCaptureContextDeserializerResult extends EmscriptenClassHandle {
    getContext: () => DataCaptureContext;
    getView: () => DataCaptureView | undefined;
}
interface DataCaptureContextDeserializer extends EmscriptenClassHandle {
    contextFromJson: (json: string) => DataCaptureContextDeserializerResult | null;
    updateContextFromJson: (context: DataCaptureContext, view: DataCaptureView | undefined, json: string) => DataCaptureContextDeserializerResult | null;
}
interface CaptureModeDeserializerInstance extends EmscriptenClassHandle {
    setListener: (listener: unknown) => void;
}
interface ModuleMirrorAxis {
    None: unknown;
    X: unknown;
    Y: unknown;
}
interface Vector {
    push_back: (element: unknown) => void;
}
interface WasmFrameData {
    getFrameData: () => Uint8ClampedArray;
    getWidth: () => number;
    getHeight: () => number;
    getMirrorAxis: () => unknown;
}
declare enum HintFont {
    Body = "body",
    Footnote = "footnote"
}
declare enum HintTextAlignment {
    Start = "start",
    Center = "center",
    End = "end"
}
declare enum HintWidth {
    Normal = "normal",
    Wider = "wider",
    FitText = "fitText"
}
declare enum HintHeight {
    Normal = "normal",
    Taller = "taller"
}
declare enum HintCornerStyle {
    Square = "square",
    Rounded = "rounded"
}
declare enum HintIcon {
    None = "none",
    Check = "check"
}
interface HintStyle {
    anchor: Anchor;
    verticalOffsetRatio: number;
    font: HintFont;
    textColor: string;
    textAlignment: HintTextAlignment;
    backgroundColor: string;
    hintWidth: HintWidth;
    hintHeight: HintHeight;
    hintCornerStyle: HintCornerStyle;
    hintIcon: HintIcon;
    isAnimatedToView: boolean;
}
interface PerformanceMetrics {
    processedFramesCount: number;
    redrawRequestsCount: number;
    actualRedrawsCount: number;
    frameDataPoolSize: number;
}
interface Module extends EmscriptenModule {
    callMain: () => void;
    canvas: OffscreenCanvas | undefined;
    PThread?: Record<number | string | symbol, unknown>;
    mainScriptUrlOrBlob: string;
    DataCaptureContextDeserializer: new (fsFolderPath: string, deviceId: string, deviceModel: string, domain: string, parentDomain: string, modeDeserializer: Vector, delayedRegistration: boolean, highEndBlurryRecognition: boolean, resourcePath: string) => DataCaptureContextDeserializer;
    DataCaptureContextListener: {
        extend: (target: "DataCaptureContextListener", parameters: {
            didChangeStatus: (context: DataCaptureContext, contextStatus: {
                toJson: () => string;
            }) => void;
            didStartObservingContext: (context: DataCaptureContext) => void;
        }) => new () => EmscriptenClassHandle;
    };
    HintPresenter: {
        extend: (target: "HintPresenter", parameters: {
            showHint: (hint: string, style: string) => void;
            updateHint: (style: string) => void;
            hideHint: () => void;
        }) => new () => EmscriptenClassHandle;
    };
    ImageBufferFrameSource: new (mirroredAxis: unknown, isCameraFrameSource: boolean) => DataCaptureImageBufferFrameSource;
    ImageBufferFormat: {
        Grayscale8: unknown;
        Rgb888: unknown;
        Rgba8888: unknown;
    };
    Axis: ModuleMirrorAxis;
    NeedsRedrawDelegate: {
        extend: (target: "NeedsRedrawDelegate", parameters: {
            setNeedsRedrawIn: (inMs: number) => void;
        }) => new () => EmscriptenClassHandle;
    };
    GestureRecognizer: {
        extend: (target: "GestureRecognizer", parameters: {
            setGestureListener(gestureListener: GestureListener, flags: number): void;
        }) => new () => GestureRecognizer;
    };
    VectorDataCaptureModeDeserializer: new () => Vector;
    allocateUint8Array: (length: number) => number;
    deleteUint8Array: (adress: number) => void;
    DataDecoding: {
        extend: (target: "DataDecoding", options: {
            decode: (rawData: ArrayBuffer, encodingRanges: string) => string;
        }) => new () => EmscriptenClassHandle;
    };
    setDataDecoding: (decoder: unknown) => void;
    LicenseUtils: {
        getBlinkIdLicenseKey: (scanditLicense: string) => string;
    };
    Feedback: {
        extend: (target: "Feedback", parameters: {
            emit: () => void;
        }) => new () => EmscriptenClassHandle;
    };
    dispose: () => void;
}
type AugmentedWorker<M extends Module> = Worker & {
    Module: M;
    OffscreenCanvas: new (w: number, h: number) => OffscreenCanvas;
};
type EngineWorkerResponse<C extends DataCaptureActionMessageKey> = WorkerResponse<C> extends Promise<void> | void ? Promise<void> | void : {
    payload: WorkerResponse<C>;
    transferables?: Transferable[];
};
interface ModuleHandler<M extends Module> {
    get: () => M;
    set: (v: M) => void;
}

interface FrameData {
    readonly width: number;
    readonly height: number;
    readonly isFrameSourceMirrored: boolean;
    toBlob(type?: string, quality?: number): Promise<Blob | null>;
    getData(): Promise<Uint8ClampedArray | null>;
}
type PrivateLoadableFrameData = Omit<FrameData, "getData" | "toBlob"> & {
    frameId: number;
};
/**
 * Adds some function to the passed frame data object to let the user load the frame data.
 */
declare function convertToPublicFrameData(loadableFrameData: PrivateLoadableFrameData, context: DataCaptureContext$1): FrameData;

interface LoadLibraryParameters {
    libraryLocation: string;
    locationPath: string;
    preloadEngine: boolean;
    writableDataPathOverride?: string;
    overrideSimdSupport: OverrideState;
    overrideThreadsSupport: OverrideState;
    verifyResponseHash: boolean;
    onProgress?: (info: ProgressInfo) => void;
    referredOrigin?: string;
}
interface CreateContextParameters {
    context: DataCaptureContextJSON;
    deviceId: string;
    delayedRegistration: boolean;
    highEndBlurryRecognition: boolean;
    appName: string | null;
    parentDomain: string;
}
interface UpdateContextParameters {
    context: DataCaptureContextJSON;
    view: {
        width: number;
        height: number;
        visible: boolean;
    } | null;
}
interface SetFrameSourceParameters {
    mirrorAxis: PrivateMirrorAxis;
    isCameraFrameSource: boolean;
}
type ProcessFrameParameters = FrameCapture;
interface ReportCameraPropertiesParameters {
    deviceId: string;
    hasAutofocus: boolean;
    isFrontFacing: boolean;
}
interface WorkerFunctions {
    getOffscreenCanvas: () => OffscreenCanvas | undefined;
    postMessage: (message: DataCaptureCallbackMessage, transfer?: Transferable[]) => void;
}
/**
 * DataCaptureEngine is an abstraction of the engine, it is created by the engine worker
 * and should be used as a singleton. It calls the underlying engine methods directly.
 */
declare class DataCaptureEngine<M extends Module> {
    private static get3dPartyLicenseKeyMethodName;
    context: DataCaptureContext;
    lastUsedModuleMirrorAxis: unknown;
    view: DataCaptureView | undefined;
    protected readonly MAX_NUMBER_OF_IMAGES_IN_FRAME_DATA_POOL: number;
    protected readonly moduleHandler: ModuleHandler<M>;
    protected readonly redrawInterval: number;
    protected readonly redrawRequests: number[];
    protected readonly workerFunctions: WorkerFunctions;
    protected _isDrawLoopRunning: boolean;
    protected contextDeserializer: DataCaptureContextDeserializer | undefined;
    protected frameDataPool: Map<number, Uint8ClampedArray>;
    protected imageFrameSource?: DataCaptureImageBufferFrameSource;
    protected lastFrameCounter: number;
    protected libraryLoadingPromise: Promise<void> | undefined;
    protected loopTimeoutId?: ReturnType<typeof setTimeout>;
    protected resourcePath: string;
    protected writableDataPath: string;
    protected poorMansBenchmarkLogs: boolean;
    protected parentDomain: string;
    protected readonly writableDataPathPreload: string;
    protected readonly writableDataPathStandard: string;
    protected readonly resourceFilesSubfolder: string;
    protected performanceMetricsReporterTimer: ReturnType<typeof setTimeout> | undefined;
    protected performanceMetrics: PerformanceMetrics;
    protected gestureRecognizer: GestureRecognizer | null;
    private gestureListener;
    constructor(moduleHandler: ModuleHandler<M>, workerFunctions: WorkerFunctions);
    get Module(): M;
    set isDrawLoopRunning(newValue: boolean);
    get isDrawLoopRunning(): boolean;
    setPoorMansBenchmarkLogs(enable: boolean): void;
    convertToLoadableFrameData(frameData: WasmFrameData): PrivateLoadableFrameData;
    createContext(createContextJSON: CreateContextParameters): EngineWorkerResponse<"createContext">;
    onTap(point: PointJSON): void;
    startReportingPerformanceMetrics(): void;
    reportPerformanceMetrics(): Promise<void>;
    deleteFrameData(frameId: number): void;
    dispose(): EngineWorkerResponse<"dispose">;
    flushAnalytics(): void;
    extractCentaurusLicense(scanditLicenseKey: string): EngineWorkerResponse<"extractCentaurusLicense">;
    getModeDeserializers(): Vector;
    loadLibrary(parameters: LoadLibraryParameters): EngineWorkerResponse<"loadLibrary">;
    processFrame(parameters: ProcessFrameParameters): EngineWorkerResponse<"processFrame">;
    reportCameraProperties(properties: ReportCameraPropertiesParameters): EngineWorkerResponse<"reportCameraProperties">;
    requestFrameData(frameId: number): EngineWorkerResponse<"requestFrameData">;
    scheduleRedraw(view: DataCaptureView, redrawInMs: number): void;
    sendViewRefreshCommands(commands: Uint8Array): void;
    setFrameSource(mirrorAxis: PrivateMirrorAxis, isCameraFrameSource: boolean): EngineWorkerResponse<"setFrameSource">;
    /**
     * The draw loop check at regular interval if any redraw request were made by the engine.
     * If a redraw is necessary, it gathers and sends drawing commands to the main thread.
     */
    startDrawLoop(view: DataCaptureView): void;
    updateContext(contextUpdateParameters: UpdateContextParameters): EngineWorkerResponse<"updateContext">;
    onDocumentVisibilityChange(state: DocumentVisibilityState): void;
    protected getNextFrameId(): number;
    protected getWasmDynamicLibraries(coreWasmURI: string): string[];
    protected getWasmCoreExpectedHash(simdSupport: boolean, threadsSupport: boolean): string;
    protected getWasmCoreFileName(simdSupport: boolean, threadsSupport: boolean): string;
    protected getWasmMetadata(): Record<string, {
        bytes: number;
    }>;
    protected getWasmSideModuleFileName(): string;
    private _loadProgressCallback;
    /**
     * Redraw requests are scheduled at [now + redrawInMs], so when pushed they must be sorted
     * in chronological order so that we can later easily check if we need to redraw by checking
     * the first element.
     * @param redrawInMs
     */
    private addRedrawRequest;
    private contextDidChangeStatus;
    private didStartObservingContext;
    private mapMirrorAxisOnModule;
    private setView;
    private setViewRefreshHandler;
    private setupDataDecoding;
    private start;
    private getWritableDataPath;
    private setup;
}

declare enum MeteringMode {
    CONTINUOUS = "continuous",
    MANUAL = "manual",
    NONE = "none",
    SINGLE_SHOT = "single-shot"
}
declare enum CameraResolutionConstraint {
    ULTRA_HD = 0,
    FULL_HD = 1,
    HD = 2,
    SD = 3,
    NONE = 4
}
interface ExtendedMediaTrackCapabilities extends MediaTrackCapabilities {
    exposureCompensation?: DoubleRange;
    exposureMode?: MeteringMode[];
    exposureTime?: DoubleRange;
    focusDistance?: DoubleRange;
    focusMode?: MeteringMode[];
    torch?: boolean;
    zoom?: DoubleRange;
}
interface ExtendedMediaTrackConstraintSet extends MediaTrackConstraintSet {
    exposureCompensation?: ConstrainDouble | number;
    exposureMode?: MeteringMode;
    exposureTime?: ConstrainDouble | number;
    focusDistance?: ConstrainDouble | number;
    focusMode?: MeteringMode;
    torch?: boolean;
    zoom?: ConstrainDouble | number;
}
interface GUI {
    isCameraRecoveryVisible: () => boolean;
    setCameraRecoveryVisible: (visible: boolean) => void;
}
interface FrameCapture {
    colorType?: ColorType;
    data: Uint8ClampedArray;
    height: number;
    width: number;
}
declare enum CameraManagerEvent {
    CAMERA_PROPERTIES = "cameraProperties",
    CAMERA_ACCESS_ERROR = "cameraAccessError"
}
type CameraManagerEventParameters<C> = C extends CameraManagerEvent.CAMERA_PROPERTIES ? ReportCameraPropertiesParameters : C extends CameraManagerEvent.CAMERA_ACCESS_ERROR ? any : never;
/**
 * A barcode picker utility class used to handle camera interaction.
 */
declare class CameraManager {
    private static readonly autofocusIntervalMs;
    private static readonly cameraAccessTimeoutMs;
    private static readonly getCapabilitiesTimeoutMs;
    private static readonly manualFocusWaitTimeoutMs;
    private static readonly manualToAutofocusResumeTimeoutMs;
    private static readonly noCameraErrorParameters;
    private static readonly notReadableErrorParameters;
    private static readonly videoMetadataCheckIntervalMs;
    private static readonly videoMetadataCheckTimeoutMs;
    private static MIRRORED_CLASS_NAME;
    private static _instance;
    activeCamera?: DeviceCamera$1;
    activeCameraSettings?: CameraSettings;
    canvas: HTMLCanvasElement;
    gui: GUI;
    selectedCamera?: DeviceCamera$1;
    videoElement: HTMLVideoElement;
    private readonly checkCameraVideoStreamAccessIfVisibleListener;
    private readonly handleWebGLContextLostListener;
    private readonly listeners;
    private readonly mirrorImageOverrides;
    private readonly postStreamInitializationListener;
    private readonly triggerFatalError;
    private readonly triggerManualFocusListener;
    private readonly triggerZoomMoveListener;
    private readonly triggerZoomStartListener;
    private readonly videoResizeListener;
    private readonly videoTrackEndedListener;
    private readonly videoTrackMuteListener;
    private _canvas2dContext;
    private _canvasWebGLContext;
    private _glFrameReaders;
    private _frameReaderType;
    private _mediaStream?;
    private abortedCameraInitializationResolveCallback?;
    private autofocusInterval;
    private cameraAccessRejectCallback?;
    private cameraAccessTimeout;
    private cameraInitializationPromise?;
    private cameraPosition;
    private cameraSetupPromise?;
    private getCapabilitiesTimeout;
    private manualFocusWaitTimeout;
    private manualToAutofocusResumeTimeout;
    private mediaTrackCapabilities?;
    private mediaTrackCapabilitiesPromise?;
    private mediaTrackCapabilitiesPromiseResolver?;
    private pinchToZoomDistance?;
    private pinchToZoomEnabled;
    private pinchToZoomInitialZoom;
    private selectedCameraSettings?;
    private tapToFocusEnabled;
    private torchEnabled;
    private torchToggleEnabled;
    private videoMetadataCheckInterval;
    private isWebGLSupported;
    constructor();
    recycle(pixelsData: Uint8ClampedArray): void;
    get mediaStream(): MediaStream | undefined;
    set mediaStream(stream: MediaStream | undefined);
    private get canvas2dContext();
    private get canvasWebGLContext();
    static instance(): CameraManager;
    getCurrentFrame(): FrameCapture | undefined;
    requestVideoFrame(scheduledFunction: FrameRequestCallback | VideoFrameRequestCallback): number;
    cancelVideoFrame(id: number): void;
    addListener<E extends CameraManagerEvent>(event: CameraManagerEvent, listener: (details: CameraManagerEventParameters<E>) => void): void;
    applyCameraSettings(cameraSettings?: CameraSettings): Promise<void>;
    captureImage(): FrameCapture | null;
    initializeCameraWithSettings(camera?: DeviceCamera$1, cameraSettings?: CameraSettings): Promise<void>;
    isMirrorImageEnabled(): boolean;
    isPinchToZoomEnabled(): boolean;
    isTapToFocusEnabled(): boolean;
    isTorchAvailable(): Promise<boolean>;
    playVideo(): Promise<void>;
    reinitializeCamera(): Promise<void>;
    removeListener<E extends CameraManagerEvent>(event: CameraManagerEvent, listenerToRemove?: (details: CameraManagerEventParameters<E>) => void): void;
    setCameraPosition(cameraPosition: CameraPosition): Promise<void>;
    setExposure(exposure: {
        compensation?: number;
        time?: number;
    }): Promise<void>;
    setFocus(manualLensPosition: number): Promise<void>;
    setFrameRate(frameRate: {
        min?: number;
        max?: number;
    }): Promise<void>;
    setInitialCameraPosition(cameraPosition: CameraPosition): void;
    setInteractionOptions(torchToggleEnabled: boolean, tapToFocusEnabled: boolean, pinchToZoomEnabled: boolean): void;
    setMirrorImageEnabled(enabled: boolean, override: boolean): void;
    setPinchToZoomEnabled(enabled: boolean): void;
    setSelectedCamera(camera?: DeviceCamera$1): void;
    setSelectedCameraSettings(cameraSettings?: CameraSettings): void;
    setTapToFocusEnabled(enabled: boolean): void;
    setTorchEnabled(enabled: boolean): Promise<void>;
    setZoom(zoomFactor: number): Promise<void>;
    setupCameras(): Promise<void>;
    pauseStream(): void;
    resumeStream(): void;
    stopStream(cameraInitializationFailure?: boolean): Promise<void>;
    stopVideoTracks(): void;
    toggleTorch(): Promise<void>;
    updateCanvasVideoImage(): void;
    waitForCapabilities(): Promise<void>;
    setFrameReaderType(type: ColorType): void;
    allowPictureInPicture(allow: boolean): Promise<void>;
    private accessAutoselectedCamera;
    private accessInitialCamera;
    /**
     * When a context has been created for a canvas, it is not possible to get another one from another type.
     * This function re-creates a new canvas based on the existing one.
     */
    private recreateCanvas;
    private captureImageFor2dContext;
    private captureImageForWebGLContext;
    private checkCameraAccess;
    private checkCameraVideoStreamAccessIfVisible;
    private checkVideoMetadata;
    private disablePinchToZoomListeners;
    private disableTapToFocusListeners;
    private emit;
    private enablePinchToZoomListeners;
    private enableTapToFocusListeners;
    private getActiveCamera;
    private getInitialCameraResolutionConstraint;
    private handleCameraInitializationError;
    private handleVideoResize;
    private handleWebGLContextLost;
    private initializeCameraAndCheckUpdatedSettings;
    private initializeCameraForResolution;
    private initializeStreamForResolution;
    private isVideoAndContextStateValid;
    private postStreamInitialization;
    private recoverStreamIfNeeded;
    private reportCameraProperties;
    private setCameraAccessTimeout;
    private setupAutofocus;
    private setupCameraStreamVideo;
    private setupCamerasAndStream;
    private storeStreamCapabilities;
    private triggerAutoFocus;
    private triggerFocusMode;
    private triggerManualFocus;
    private triggerManualFocusForContinuous;
    private triggerManualFocusForSingleShot;
    private triggerZoomMove;
    private triggerZoomStart;
    private updateActiveCameraCurrentResolution;
    private updateStreamForResolution;
    private videoTrackEndedRecovery;
    private videoTrackMuteRecovery;
}

interface CameraJSON extends FrameSourceJSON {
    type: "camera";
    position: CameraPosition;
    settings: CameraSettingsJSON | Record<string, never>;
    desiredState: FrameSourceState;
    desiredTorchState: TorchState;
}
interface VideoFrameResolution {
    readonly width: number;
    readonly height: number;
}
declare class Camera implements FrameSource, Serializable<CameraJSON> {
    readonly label: string;
    deviceId: string;
    readonly position: CameraPosition;
    private _currentResolution?;
    private readonly cameraManager;
    private readonly type;
    private readonly webGLContextLostListener;
    private _currentState;
    private _settings;
    private _desiredTorchState;
    private _desiredState;
    private readonly listeners;
    private _context;
    private _desiredMirrorImageEnabled?;
    private _lastCaptureRequestAnimationFrame?;
    private _lastCanvasVideoPreviewAnimationFrame?;
    private _isAndroidWebView?;
    private readonly stateTransitionStrategyMap;
    private currentTransitionStrategyPromise?;
    constructor(manager?: CameraManager);
    static get default(): Camera;
    get desiredState(): FrameSourceState;
    get settings(): CameraSettings;
    get currentResolution(): VideoFrameResolution | null;
    private get context();
    private set context(value);
    private get currentState();
    static atPosition(cameraPosition: CameraPosition): Camera | null;
    static fromDeviceCamera(deviceCamera: DeviceCamera): Camera;
    switchToDesiredState(state: FrameSourceState): Promise<void>;
    getDesiredTorchState(): TorchState;
    setDesiredTorchState(desiredTorchState: TorchState): Promise<void>;
    isTorchAvailable(): Promise<boolean>;
    addListener(listener: FrameSourceListener | null): void;
    removeListener(listener: FrameSourceListener | null): void;
    applySettings(settings: CameraSettings): Promise<void>;
    toJSONObject(): CameraJSON;
    getMirrorImageEnabled(): boolean;
    setMirrorImageEnabled(enabled: boolean): Promise<void>;
    getCurrentState(): FrameSourceState;
    private setCurrentState;
    /**
     * Starts camera according to the given position. If a deviceId is set, pre-select the corresponding camera.
     * The function returns as soon as the camera has started successfully and is active. The label and
     * position properties reflect then the values found in the accessed stream.
     */
    private setupCamera;
    private notifyContext;
    private notifyListeners;
    private updateCanvasVideoImage;
    private captureAndSend;
    /**
     * Capture images from the video stream and send them to the context. If no context is set, the function will
     * stop itself until called again. While no enabled mode is present in the context, the function will schedule itself
     * again indefinitely without doing anything else.
     */
    private startSendingCapturesToWorker;
    private stopSendingCapturesToWorker;
    private transitionFromStateOffToOn;
    private transitionFromStateOffToStandby;
    private transitionFromStateOnToOff;
    private transitionFromStateOnToStandby;
    private transitionFromStateStandbyToOff;
    private transitionFromStateStandbyToOn;
    private isAndroidWebView;
}

export { DataCaptureActionMessageKey as $, DataCaptureContext$1 as A, DataCaptureContextListener as B, CameraPosition as C, DataCaptureLoader as D, ContextStatusJSON as E, FocusGestureStrategy as F, ContextStatus as G, PrivateMirrorAxis as H, DataCaptureOverlay as I, DataCaptureViewListener as J, DataCaptureViewJSON as K, DataCaptureView$1 as L, FrameData as M, PrivateLoadableFrameData as N, convertToPublicFrameData as O, PrivateChangeSet as P, OverrideState as Q, DataCaptureLoaderOptions as R, DataCaptureEngine as S, TorchState as T, Module as U, VideoResolution as V, PerformanceMetrics as W, AnyDataCaptureActionMessage as X, AugmentedWorker as Y, ModuleHandler as Z, DataCaptureCallbackMessage as _, FrameSource as a, CameraAccess$1 as a$, EngineWorkerResponse as a0, ExtractCentaurusLicenseResponse as a1, RequestFrameDataResponse as a2, WorkerResponse as a3, LoadLibraryDataCaptureAction as a4, CreateContextDataCaptureAction as a5, SetFrameSourceDataCaptureAction as a6, ProcessFrameDataCaptureAction as a7, RequestFrameDataDataCaptureAction as a8, DeleteFrameDataDataCaptureAction as a9, DataCaptureContextDeserializer as aA, CaptureModeDeserializerInstance as aB, ModuleMirrorAxis as aC, Vector as aD, WasmFrameData as aE, HintFont as aF, HintTextAlignment as aG, HintWidth as aH, HintHeight as aI, HintCornerStyle as aJ, HintIcon as aK, HintStyle as aL, LoadLibraryParameters as aM, CreateContextParameters as aN, UpdateContextParameters as aO, SetFrameSourceParameters as aP, ProcessFrameParameters as aQ, ReportCameraPropertiesParameters as aR, WorkerFunctions as aS, FrameReaderAbstract as aT, ColorType as aU, FrameCapture as aV, FrameReader as aW, CameraPosition$1 as aX, CameraResolutionConstraint$1 as aY, AspectRatio as aZ, DeviceCamera$1 as a_, VisibilityChangeAction as aa, UpdateContextDataCaptureAction as ab, DisposeDataCaptureAction as ac, FlushAnalyticsDataCaptureAction as ad, ReportCameraPropertiesDataCaptureAction as ae, SetLogLevelDataCaptureAction as af, SetPoorMansBenchmarkLogsAction as ag, ExtractCentaurusLicenseDataCaptureAction as ah, OnTapAction as ai, DataCaptureCallbackMessageKeys as aj, SuccessFeedbackWorkerMessage as ak, ShowHintWorkerMessage as al, UpdateHintWorkerMessage as am, HideHintWorkerMessage as an, PerformanceMetricsReportMessage as ao, DidTapTrackedBarcode as ap, PayloadForCommand as aq, DataCaptureWorker as ar, EmscriptenClassHandle as as, DataCaptureContext as at, DataCaptureImageBufferFrameSource as au, GestureListener as av, GestureRecognizer as aw, DataCaptureView as ax, JSONParseable as ay, DataCaptureContextDeserializerResult as az, FrameSourceState as b, MeteringMode as b0, CameraResolutionConstraint as b1, ExtendedMediaTrackCapabilities as b2, ExtendedMediaTrackConstraintSet as b3, GUI as b4, CameraManagerEvent as b5, CameraManagerEventParameters as b6, CameraManager as b7, FrameSourceListener as c, FrameSourceJSON as d, CameraJSON as e, VideoFrameResolution as f, Camera as g, CameraSettingsJSONBase as h, CameraSettingsFromJSON as i, CameraSettingsJSON as j, isCameraFrameSource as k, CameraSettings as l, CameraAccess as m, DeviceCamera as n, Change as o, PrivateDataCaptureMode as p, DataCaptureMode as q, DataCaptureModeJSON as r, PrivateDataCaptureComponent as s, DataCaptureComponentJSON as t, DataCaptureComponent as u, PrivateDataCaptureContextOptions as v, PrivateDataCaptureContext as w, DataCaptureContextCreationOptions as x, DataCaptureContextJSON as y, PrivateFrameHandler as z };
